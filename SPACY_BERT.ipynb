{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlEtTSi-JcFr",
        "outputId": "0a379ebb-a217-4b3e-aed0-39da1d369991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AWS', 'Docker', 'Git', 'Java', 'Linux', 'Machine Learning', 'PyTorch', 'Python', 'SQL', 'TensorFlow']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "SKILLS = [\n",
        "    \"Python\", \"Java\", \"C++\", \"SQL\",\n",
        "    \"Machine Learning\", \"Deep Learning\",\n",
        "    \"Data Analysis\", \"Pandas\", \"NumPy\",\n",
        "    \"TensorFlow\", \"PyTorch\",\n",
        "    \"AWS\", \"Docker\", \"Kubernetes\",\n",
        "    \"Git\", \"Linux\"\n",
        "]\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "patterns = [nlp.make_doc(skill) for skill in SKILLS]\n",
        "matcher.add(\"TECHNICAL_SKILLS\", patterns)\n",
        "\n",
        "def extract_skills(resume_text):\n",
        "    doc = nlp(resume_text)\n",
        "    matches = matcher(doc)\n",
        "    return sorted({doc[start:end].text for _, start, end in matches})\n",
        "resume_text = \"\"\"\n",
        "Software engineer skilled in Python, Java, and SQL.\n",
        "Worked on Machine Learning using TensorFlow and PyTorch.\n",
        "Experience with AWS, Docker, Git, and Linux.\n",
        "\"\"\"\n",
        "\n",
        "print(extract_skills(resume_text))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "SKILL_LIST = [\n",
        "    \"Python\", \"Java\", \"C++\", \"SQL\",\n",
        "    \"Machine Learning\", \"Deep Learning\",\n",
        "    \"Data Analysis\", \"Pandas\", \"NumPy\",\n",
        "    \"TensorFlow\", \"PyTorch\",\n",
        "    \"AWS\", \"Docker\", \"Git\", \"Linux\"\n",
        "]\n",
        "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
        "matcher.add(\"SKILLS\", [nlp.make_doc(skill) for skill in SKILL_LIST])\n",
        "\n",
        "def match_skills(text):\n",
        "    doc = nlp(text)\n",
        "    matches = matcher(doc)\n",
        "    return sorted(set(doc[start:end].text for _, start, end in matches))\n",
        "text = \"\"\"\n",
        "I have experience in Python, SQL, and Data Analysis.\n",
        "Worked with AWS and Docker, and built ML models using TensorFlow.\n",
        "\"\"\"\n",
        "print(match_skills(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2PglpRQKagO",
        "outputId": "ac0f0869-3d2a-4879-cad0-861540b25a93"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AWS', 'Data Analysis', 'Docker', 'Python', 'SQL', 'TensorFlow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.pipeline import EntityRuler\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "skill_patterns = [\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"Python\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"Java\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"SQL\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"Machine Learning\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"Deep Learning\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"Data Analysis\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"TensorFlow\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"PyTorch\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"AWS\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"Docker\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"Git\"},\n",
        "    {\"label\": \"SKILL\", \"pattern\": \"Linux\"}\n",
        "]\n",
        "ruler.add_patterns(skill_patterns)\n",
        "\n",
        "def extract_skills_ner(text):\n",
        "    doc = nlp(text)\n",
        "    return sorted({ent.text for ent in doc.ents if ent.label_ == \"SKILL\"})\n",
        "job_description = \"\"\"\n",
        "We are looking for a data engineer with strong Python and SQL skills.\n",
        "Experience in Machine Learning, AWS, Docker, and TensorFlow is required.\n",
        "Knowledge of Git and Linux is a plus.\n",
        "\"\"\"\n",
        "print(extract_skills_ner(job_description))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iJrOlt0Kyip",
        "outputId": "9bd69054-41f0-477c-eb10-e7cad9adae58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AWS', 'Docker', 'Git', 'Linux', 'Machine Learning', 'Python', 'SQL', 'TensorFlow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_skills(skills):\n",
        "    \"\"\"\n",
        "    skills: iterable of extracted skill strings\n",
        "    returns: sorted list of unique, lowercase skills\n",
        "    \"\"\"\n",
        "    return sorted({skill.strip().lower() for skill in skills})\n",
        "extracted_skills = [\n",
        "    \"Python\", \"python\", \"SQL\", \"Machine Learning\",\n",
        "    \"machine learning\", \"AWS\", \"aws\"\n",
        "]\n",
        "print(normalize_skills(extracted_skills))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m7xZyuTLMz8",
        "outputId": "36982ccb-ae4f-4ca9-8e3f-f864ccbfaed8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aws', 'machine learning', 'python', 'sql']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def store_skills(technical_skills, soft_skills):\n",
        "    \"\"\"\n",
        "    technical_skills: iterable of technical skills\n",
        "    soft_skills: iterable of soft skills\n",
        "    returns: dictionary with categorized skills\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"technical_skills\": sorted({skill.strip().lower() for skill in technical_skills}),\n",
        "        \"soft_skills\": sorted({skill.strip().lower() for skill in soft_skills})\n",
        "    }\n",
        "tech_skills = [\"Python\", \"SQL\", \"AWS\", \"Docker\", \"python\"]\n",
        "soft_skills = [\"Communication\", \"Teamwork\", \"Problem Solving\", \"communication\"]\n",
        "\n",
        "skills_dict = store_skills(tech_skills, soft_skills)\n",
        "print(skills_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp87Jjx_LUCd",
        "outputId": "4415dc20-c9ed-4250-f301-68d82b27a4c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'technical_skills': ['aws', 'docker', 'python', 'sql'], 'soft_skills': ['communication', 'problem solving', 'teamwork']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_skills(matcher_skills, ner_skills):\n",
        "    \"\"\"\n",
        "    matcher_skills: list of skills from spaCy PhraseMatcher\n",
        "    ner_skills: list of skills from spaCy NER / EntityRuler\n",
        "    returns: sorted, unique, lowercase skill list\n",
        "    \"\"\"\n",
        "    merged = set()\n",
        "\n",
        "    for skill in matcher_skills + ner_skills:\n",
        "        merged.add(skill.strip().lower())\n",
        "\n",
        "    return sorted(merged)\n",
        "skills_from_matcher = [\"Python\", \"SQL\", \"AWS\", \"Docker\"]\n",
        "skills_from_ner = [\"python\", \"Machine Learning\", \"AWS\", \"TensorFlow\"]\n",
        "\n",
        "merged_skills = merge_skills(skills_from_matcher, skills_from_ner)\n",
        "print(merged_skills)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6ZMvGQ8LbvX",
        "outputId": "6d6464bd-1f40-416b-98e3-d3ea41338eb9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['aws', 'docker', 'machine learning', 'python', 'sql', 'tensorflow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SKILL_NORMALIZATION_MAP = {\n",
        "    \"ml\": \"machine learning\",\n",
        "    \"machine learning\": \"machine learning\",\n",
        "    \"dl\": \"deep learning\",\n",
        "    \"deep learning\": \"deep learning\",\n",
        "    \"nlp\": \"natural language processing\",\n",
        "    \"natural language processing\": \"natural language processing\",\n",
        "    \"ai\": \"artificial intelligence\",\n",
        "    \"artificial intelligence\": \"artificial intelligence\",\n",
        "    \"js\": \"javascript\",\n",
        "    \"javascript\": \"javascript\"\n",
        "}\n",
        "\n",
        "def resolve_skill_conflicts(skills):\n",
        "    \"\"\"\n",
        "    skills: iterable of skill strings\n",
        "    returns: sorted list of canonical skill names\n",
        "    \"\"\"\n",
        "    resolved = set()\n",
        "\n",
        "    for skill in skills:\n",
        "        key = skill.strip().lower()\n",
        "        canonical = SKILL_NORMALIZATION_MAP.get(key, key)\n",
        "        resolved.add(canonical)\n",
        "\n",
        "    return sorted(resolved)\n",
        "raw_skills = [\n",
        "    \"ML\", \"Machine Learning\", \"DL\",\n",
        "    \"Python\", \"NLP\", \"Natural Language Processing\",\n",
        "    \"AI\", \"Artificial Intelligence\"\n",
        "]\n",
        "\n",
        "print(resolve_skill_conflicts(raw_skills))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlozrqnSLpAZ",
        "outputId": "a06781ae-d62b-417f-af66-e77701a7d26e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['artificial intelligence', 'deep learning', 'machine learning', 'natural language processing', 'python']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "sentences = [\"I know Python and machine learning.\", \"Experience with SQL databases.\"]\n",
        "master_skills = [\"python\", \"sql\", \"machine learning\", \"deep learning\"]\n",
        "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
        "skill_embeddings = model.encode(master_skills, convert_to_tensor=True)\n",
        "cos_scores = util.cos_sim(sentence_embeddings, skill_embeddings)\n",
        "threshold = 0.6\n",
        "matches = {}\n",
        "for i, sentence in enumerate(sentences):\n",
        "    matched_skills = [master_skills[j] for j, score in enumerate(cos_scores[i]) if score > threshold]\n",
        "    matches[sentence] = matched_skills\n",
        "\n",
        "print(matches)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJoTbKKWMMo8",
        "outputId": "07c820bb-ec96-403e-9ff4-0c89481b479f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I know Python and machine learning.': ['python'], 'Experience with SQL databases.': ['sql']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "sentences = [\"I know Python and ML.\", \"I enjoy team building.\", \"Experienced in SQL.\"]\n",
        "master_skills = [\"python\", \"machine learning\", \"sql\", \"deep learning\"]\n",
        "sentence_embeddings = model.encode(sentences, convert_to_tensor=True)\n",
        "skill_embeddings = model.encode(master_skills, convert_to_tensor=True)\n",
        "cos_scores = util.cos_sim(sentence_embeddings, skill_embeddings)\n",
        "threshold = 0.6\n",
        "matches = {}\n",
        "for i, sentence in enumerate(sentences):\n",
        "    matched_skills = [master_skills[j] for j, score in enumerate(cos_scores[i]) if score > threshold]\n",
        "    matches[sentence] = matched_skills\n",
        "\n",
        "print(matches)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9GXubW-Ml-l",
        "outputId": "0ad5f5de-d5a1-4cef-89f9-efe6d909fa55"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I know Python and ML.': ['python'], 'I enjoy team building.': [], 'Experienced in SQL.': ['sql']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_skills = [\"python\", \"communication\", \"ml\", \"teamwork\", \"sql\"]\n",
        "skill_mapping = {\n",
        "    \"technical\": [\"python\", \"java\", \"sql\", \"machine learning\", \"docker\", \"git\", \"ml\"],\n",
        "    \"soft\": [\"communication\", \"teamwork\", \"leadership\", \"problem solving\"]\n",
        "}\n",
        "categorized_skills = {\"technical_skills\": [], \"soft_skills\": []}\n",
        "\n",
        "for skill in merged_skills:\n",
        "    if skill.lower() in skill_mapping[\"technical\"]:\n",
        "        categorized_skills[\"technical_skills\"].append(skill)\n",
        "    elif skill.lower() in skill_mapping[\"soft\"]:\n",
        "        categorized_skills[\"soft_skills\"].append(skill)\n",
        "\n",
        "print(categorized_skills)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fCeE2dENBdd",
        "outputId": "7518e58f-6bf1-4714-dd51-8742710a09bd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'technical_skills': ['python', 'ml', 'sql'], 'soft_skills': ['communication', 'teamwork']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "master_skills = [\"python\", \"java\", \"sql\", \"machine learning\", \"deep learning\",\n",
        "                 \"docker\", \"git\", \"communication\", \"teamwork\", \"leadership\", \"problem solving\"]\n",
        "abbreviation_map = {\"ml\": \"machine learning\"}\n",
        "skill_mapping = {\n",
        "    \"technical\": [\"python\", \"java\", \"sql\", \"machine learning\", \"deep learning\", \"docker\", \"git\"],\n",
        "    \"soft\": [\"communication\", \"teamwork\", \"leadership\", \"problem solving\"]\n",
        "}\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "patterns = [nlp(skill) for skill in master_skills]\n",
        "matcher.add(\"SKILLS\", patterns)\n",
        "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def extract_skills(resume_text, similarity_threshold=0.6):\n",
        "    doc = nlp(resume_text)\n",
        "    matcher_matches = matcher(doc)\n",
        "    skills_matcher = [doc[start:end].text.lower() for _, start, end in matcher_matches]\n",
        "    skills_ner = [ent.text.lower() for ent in doc.ents if ent.label_ in [\"ORG\", \"PRODUCT\", \"SKILL\"]]\n",
        "    merged_skills = set(skills_matcher + skills_ner)\n",
        "    merged_skills = [abbreviation_map.get(skill, skill) for skill in merged_skills]\n",
        "    sentence_embeddings = bert_model.encode([resume_text], convert_to_tensor=True)\n",
        "    skill_embeddings = bert_model.encode(master_skills, convert_to_tensor=True)\n",
        "    cos_scores = util.cos_sim(sentence_embeddings, skill_embeddings)[0]\n",
        "\n",
        "    for i, score in enumerate(cos_scores):\n",
        "        if score > similarity_threshold:\n",
        "            merged_skills.append(master_skills[i].lower())\n",
        "    merged_skills = list(set(merged_skills))\n",
        "    categorized_skills = {\"technical_skills\": [], \"soft_skills\": []}\n",
        "    for skill in merged_skills:\n",
        "        if skill in skill_mapping[\"technical\"]:\n",
        "            categorized_skills[\"technical_skills\"].append(skill)\n",
        "        elif skill in skill_mapping[\"soft\"]:\n",
        "            categorized_skills[\"soft_skills\"].append(skill)\n",
        "\n",
        "    return categorized_skills\n",
        "resume_text = \"Experienced in Python, ML, SQL and great teamwork skills.\"\n",
        "skills = extract_skills(resume_text)\n",
        "print(skills)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvewT4j4NOxi",
        "outputId": "eed630a0-2bd2-4724-8f38-aa21e2064534"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'technical_skills': ['machine learning', 'sql'], 'soft_skills': ['teamwork']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "standardization_map = {\n",
        "    \"ml\": \"machine learning\",\n",
        "    \"machine learning\": \"machine learning\",\n",
        "    \"deep learning\": \"deep learning\",\n",
        "    \"python\": \"python\",\n",
        "    \"sql\": \"sql\",\n",
        "    \"teamwork\": \"teamwork\",\n",
        "    \"communication\": \"communication\"\n",
        "}\n",
        "extracted_skills = [\"ML\", \"machine learning\", \"Python\", \"SQL\", \"teamwork\"]\n",
        "standardized_skills = set()\n",
        "for skill in extracted_skills:\n",
        "    skill_lower = skill.lower()\n",
        "    standardized_skills.add(standardization_map.get(skill_lower, skill_lower))\n",
        "\n",
        "print(standardized_skills)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2MhwLVtNUOS",
        "outputId": "318e3ee3-49b9-48ac-cd48-5fd163722c1a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'machine learning', 'teamwork', 'python', 'sql'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spacy_skills = [\"python\", \"machine learning\", \"sql\"]\n",
        "bert_skills = [\"python\", \"ml\", \"deep learning\"]\n",
        "standardization_map = {\n",
        "    \"ml\": \"machine learning\",\n",
        "    \"machine learning\": \"machine learning\",\n",
        "    \"deep learning\": \"deep learning\",\n",
        "    \"python\": \"python\",\n",
        "    \"sql\": \"sql\"\n",
        "}\n",
        "spacy_skills_std = set(standardization_map.get(skill.lower(), skill.lower()) for skill in spacy_skills)\n",
        "bert_skills_std = set(standardization_map.get(skill.lower(), skill.lower()) for skill in bert_skills)\n",
        "final_skills = spacy_skills_std.union(bert_skills_std - spacy_skills_std)\n",
        "\n",
        "print(final_skills)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiO928VxN1vq",
        "outputId": "ad53458c-8288-43c5-8d2d-4c63116c3573"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'machine learning', 'python', 'sql', 'deep learning'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "final_skills = {\n",
        "    \"technical_skills\": [\"python\", \"machine learning\", \"sql\", \"deep learning\"],\n",
        "    \"soft_skills\": [\"teamwork\", \"communication\"]\n",
        "}\n",
        "with open(\"final_skills.json\", \"w\") as f:\n",
        "    json.dump(final_skills, f, indent=4)\n",
        "\n",
        "print(\"Saved final_skills.json successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXqEVVpdONR6",
        "outputId": "dcd129ea-a612-407e-8f06-b5679e210f42"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved final_skills.json successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_skills = {\"python\", \"machine learning\", \"sql\", \"teamwork\", \"communication\"}\n",
        "spacy_skills = {\"python\", \"machine learning\", \"sql\"}\n",
        "bert_skills = {\"python\", \"ml\", \"deep learning\", \"teamwork\"}\n",
        "combined_skills = {\"python\", \"machine learning\", \"sql\", \"deep learning\", \"teamwork\", \"communication\"}\n",
        "standardization_map = {\n",
        "    \"ml\": \"machine learning\",\n",
        "    \"machine learning\": \"machine learning\",\n",
        "    \"deep learning\": \"deep learning\",\n",
        "    \"python\": \"python\",\n",
        "    \"sql\": \"sql\",\n",
        "    \"teamwork\": \"teamwork\",\n",
        "    \"communication\": \"communication\"\n",
        "}\n",
        "bert_skills_std = set(standardization_map.get(skill.lower(), skill.lower()) for skill in bert_skills)\n",
        "def evaluate(predicted, ground_truth):\n",
        "    predicted_set = set(predicted)\n",
        "    ground_truth_set = set(ground_truth)\n",
        "\n",
        "    true_positives = len(predicted_set & ground_truth_set)\n",
        "    false_positives = len(predicted_set - ground_truth_set)\n",
        "    false_negatives = len(ground_truth_set - predicted_set)\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    return precision, recall, f1\n",
        "pipelines = {\n",
        "    \"spaCy-only\": spacy_skills,\n",
        "    \"BERT-only\": bert_skills_std,\n",
        "    \"Combined\": combined_skills\n",
        "}\n",
        "\n",
        "print(\"Skill Extraction Pipeline Comparison:\")\n",
        "for name, skills in pipelines.items():\n",
        "    precision, recall, f1 = evaluate(skills, ground_truth_skills)\n",
        "    print(f\"{name}: Precision={precision:.2f}, Recall={recall:.2f}, F1={f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juQRoUjLPK4x",
        "outputId": "4a151ace-7bab-40f5-dbdf-682ccfe03f1e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skill Extraction Pipeline Comparison:\n",
            "spaCy-only: Precision=1.00, Recall=0.60, F1=0.75\n",
            "BERT-only: Precision=0.75, Recall=0.60, F1=0.67\n",
            "Combined: Precision=0.83, Recall=1.00, F1=0.91\n"
          ]
        }
      ]
    }
  ]
}